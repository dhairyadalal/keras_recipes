{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Tensorflow **\n",
    "1. declare symbolic variables\n",
    "2. define symbolic functio\n",
    "3. Bind valuess to symbolic representation\n",
    "4. Run computation against TF graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note exploration covers chapters 1-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# define variables\n",
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "\n",
    "# defie function\n",
    "add = tf.add(a,b)\n",
    "\n",
    "# start tf sessio\n",
    "sess = tf.Session()\n",
    "\n",
    "binding = {a:1.5, b:2.5} # bid values to variables \n",
    "\n",
    "print(sess.run(add, feed_dict = binding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Keras Example: Pima Indians **\n",
    "\n",
    "Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n",
      "[  6.    148.     72.     35.      0.     33.6     0.627  50.      1.   ]\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "dataset = numpy.loadtxt(\"code/chapter_07/pima-indians-diabetes.csv\", delimiter = \",\")\n",
    "\n",
    "print(dataset.shape)\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6.    148.     72.     35.      0.     33.6     0.627  50.   ]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "X = dataset[:,0:8]\n",
    "print(X[0])\n",
    "\n",
    "Y = dataset[:,8]\n",
    "print(Y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Define Model **\n",
    "\n",
    "relu -> rectifier activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu')) # Input layer\n",
    "model.add(Dense(8, activation='relu'))               # Hidden Layer\n",
    "model.add(Dense(1, activation='sigmoid'))            # Output -> returns 0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished.\n"
     ]
    }
   ],
   "source": [
    "# Fit Model\n",
    "model.fit(X,Y, epochs = 150, batch_size=10, verbose=0)\n",
    "print(\"finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 107us/step\n",
      "\n",
      "acc: 74.61%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Model\n",
    "scores = model.evaluate(X,Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Keras Features: Validation Split **\n",
    "\n",
    "Keras can separate a portion of your training data into a validation dataset and evaluate the performance of your model on that validation dataset each epoch. You can do this by setting the validation split argument on the fit() function to a percentage of the size of your training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 514 samples, validate on 254 samples\n",
      "Epoch 1/50\n",
      "514/514 [==============================] - 0s 701us/step - loss: 0.5069 - acc: 0.7724 - val_loss: 0.5131 - val_acc: 0.7677\n",
      "Epoch 2/50\n",
      "514/514 [==============================] - 0s 155us/step - loss: 0.4734 - acc: 0.7704 - val_loss: 0.5372 - val_acc: 0.7756\n",
      "Epoch 3/50\n",
      "514/514 [==============================] - 0s 156us/step - loss: 0.4806 - acc: 0.7685 - val_loss: 0.5172 - val_acc: 0.7559\n",
      "Epoch 4/50\n",
      "514/514 [==============================] - 0s 142us/step - loss: 0.4819 - acc: 0.7607 - val_loss: 0.5645 - val_acc: 0.7441\n",
      "Epoch 5/50\n",
      "514/514 [==============================] - 0s 161us/step - loss: 0.4883 - acc: 0.7510 - val_loss: 0.5053 - val_acc: 0.7717\n",
      "Epoch 6/50\n",
      "514/514 [==============================] - 0s 159us/step - loss: 0.4897 - acc: 0.7743 - val_loss: 0.5277 - val_acc: 0.7559\n",
      "Epoch 7/50\n",
      "514/514 [==============================] - 0s 156us/step - loss: 0.4673 - acc: 0.7665 - val_loss: 0.5178 - val_acc: 0.7638\n",
      "Epoch 8/50\n",
      "514/514 [==============================] - 0s 151us/step - loss: 0.4707 - acc: 0.7607 - val_loss: 0.5416 - val_acc: 0.7638\n",
      "Epoch 9/50\n",
      "514/514 [==============================] - 0s 145us/step - loss: 0.4962 - acc: 0.7626 - val_loss: 0.5307 - val_acc: 0.7638\n",
      "Epoch 10/50\n",
      "514/514 [==============================] - 0s 158us/step - loss: 0.4794 - acc: 0.7802 - val_loss: 0.5362 - val_acc: 0.7480\n",
      "Epoch 11/50\n",
      "514/514 [==============================] - 0s 160us/step - loss: 0.4856 - acc: 0.7626 - val_loss: 0.5175 - val_acc: 0.7480\n",
      "Epoch 12/50\n",
      "514/514 [==============================] - 0s 153us/step - loss: 0.4661 - acc: 0.7646 - val_loss: 0.5268 - val_acc: 0.7756\n",
      "Epoch 13/50\n",
      "514/514 [==============================] - 0s 143us/step - loss: 0.4684 - acc: 0.7588 - val_loss: 0.5330 - val_acc: 0.7362\n",
      "Epoch 14/50\n",
      "514/514 [==============================] - 0s 151us/step - loss: 0.4703 - acc: 0.7743 - val_loss: 0.5371 - val_acc: 0.7717\n",
      "Epoch 15/50\n",
      "514/514 [==============================] - 0s 146us/step - loss: 0.4935 - acc: 0.7646 - val_loss: 0.5172 - val_acc: 0.7559\n",
      "Epoch 16/50\n",
      "514/514 [==============================] - 0s 147us/step - loss: 0.4659 - acc: 0.7704 - val_loss: 0.5748 - val_acc: 0.7283\n",
      "Epoch 17/50\n",
      "514/514 [==============================] - 0s 160us/step - loss: 0.4904 - acc: 0.7626 - val_loss: 0.5374 - val_acc: 0.7402\n",
      "Epoch 18/50\n",
      "514/514 [==============================] - 0s 142us/step - loss: 0.4889 - acc: 0.7607 - val_loss: 0.5303 - val_acc: 0.7480\n",
      "Epoch 19/50\n",
      "514/514 [==============================] - 0s 151us/step - loss: 0.4980 - acc: 0.7568 - val_loss: 0.6587 - val_acc: 0.6969\n",
      "Epoch 20/50\n",
      "514/514 [==============================] - 0s 164us/step - loss: 0.4781 - acc: 0.7724 - val_loss: 0.5325 - val_acc: 0.7559\n",
      "Epoch 21/50\n",
      "514/514 [==============================] - 0s 159us/step - loss: 0.4854 - acc: 0.7568 - val_loss: 0.5447 - val_acc: 0.7638\n",
      "Epoch 22/50\n",
      "514/514 [==============================] - 0s 148us/step - loss: 0.4762 - acc: 0.7763 - val_loss: 0.5280 - val_acc: 0.7677\n",
      "Epoch 23/50\n",
      "514/514 [==============================] - 0s 166us/step - loss: 0.4646 - acc: 0.7763 - val_loss: 0.5238 - val_acc: 0.7559\n",
      "Epoch 24/50\n",
      "514/514 [==============================] - 0s 155us/step - loss: 0.4816 - acc: 0.7724 - val_loss: 0.5616 - val_acc: 0.7244\n",
      "Epoch 25/50\n",
      "514/514 [==============================] - 0s 153us/step - loss: 0.4722 - acc: 0.7646 - val_loss: 0.5895 - val_acc: 0.7402\n",
      "Epoch 26/50\n",
      "514/514 [==============================] - 0s 153us/step - loss: 0.4765 - acc: 0.7685 - val_loss: 0.5377 - val_acc: 0.7638\n",
      "Epoch 27/50\n",
      "514/514 [==============================] - 0s 150us/step - loss: 0.5076 - acc: 0.7354 - val_loss: 0.5959 - val_acc: 0.7087\n",
      "Epoch 28/50\n",
      "514/514 [==============================] - 0s 165us/step - loss: 0.4731 - acc: 0.7704 - val_loss: 0.5621 - val_acc: 0.7677\n",
      "Epoch 29/50\n",
      "514/514 [==============================] - 0s 169us/step - loss: 0.4675 - acc: 0.7977 - val_loss: 0.5754 - val_acc: 0.7205\n",
      "Epoch 30/50\n",
      "514/514 [==============================] - 0s 178us/step - loss: 0.4727 - acc: 0.7743 - val_loss: 0.5423 - val_acc: 0.7795\n",
      "Epoch 31/50\n",
      "514/514 [==============================] - 0s 169us/step - loss: 0.4828 - acc: 0.7665 - val_loss: 0.5170 - val_acc: 0.7795\n",
      "Epoch 32/50\n",
      "514/514 [==============================] - 0s 166us/step - loss: 0.4680 - acc: 0.7724 - val_loss: 0.5353 - val_acc: 0.7598\n",
      "Epoch 33/50\n",
      "514/514 [==============================] - 0s 164us/step - loss: 0.4896 - acc: 0.7490 - val_loss: 0.5121 - val_acc: 0.7520\n",
      "Epoch 34/50\n",
      "514/514 [==============================] - 0s 167us/step - loss: 0.4955 - acc: 0.7432 - val_loss: 0.6686 - val_acc: 0.6575\n",
      "Epoch 35/50\n",
      "514/514 [==============================] - 0s 147us/step - loss: 0.5005 - acc: 0.7160 - val_loss: 0.5602 - val_acc: 0.7087\n",
      "Epoch 36/50\n",
      "514/514 [==============================] - 0s 169us/step - loss: 0.4986 - acc: 0.7510 - val_loss: 0.5500 - val_acc: 0.7480\n",
      "Epoch 37/50\n",
      "514/514 [==============================] - 0s 158us/step - loss: 0.4870 - acc: 0.7510 - val_loss: 0.5479 - val_acc: 0.7598\n",
      "Epoch 38/50\n",
      "514/514 [==============================] - 0s 162us/step - loss: 0.4642 - acc: 0.7704 - val_loss: 0.4934 - val_acc: 0.7717\n",
      "Epoch 39/50\n",
      "514/514 [==============================] - 0s 159us/step - loss: 0.4550 - acc: 0.7860 - val_loss: 0.5502 - val_acc: 0.7480\n",
      "Epoch 40/50\n",
      "514/514 [==============================] - 0s 157us/step - loss: 0.4633 - acc: 0.7743 - val_loss: 0.5688 - val_acc: 0.7559\n",
      "Epoch 41/50\n",
      "514/514 [==============================] - 0s 163us/step - loss: 0.4951 - acc: 0.7315 - val_loss: 0.5970 - val_acc: 0.7283\n",
      "Epoch 42/50\n",
      "514/514 [==============================] - 0s 172us/step - loss: 0.4952 - acc: 0.7607 - val_loss: 0.5222 - val_acc: 0.7756\n",
      "Epoch 43/50\n",
      "514/514 [==============================] - 0s 157us/step - loss: 0.4687 - acc: 0.7665 - val_loss: 0.5296 - val_acc: 0.7795\n",
      "Epoch 44/50\n",
      "514/514 [==============================] - 0s 171us/step - loss: 0.4775 - acc: 0.7646 - val_loss: 0.5361 - val_acc: 0.7795\n",
      "Epoch 45/50\n",
      "514/514 [==============================] - 0s 165us/step - loss: 0.4691 - acc: 0.7665 - val_loss: 0.5693 - val_acc: 0.7598\n",
      "Epoch 46/50\n",
      "514/514 [==============================] - 0s 161us/step - loss: 0.4681 - acc: 0.7646 - val_loss: 0.5178 - val_acc: 0.7638\n",
      "Epoch 47/50\n",
      "514/514 [==============================] - 0s 161us/step - loss: 0.4725 - acc: 0.7568 - val_loss: 0.5263 - val_acc: 0.7598\n",
      "Epoch 48/50\n",
      "514/514 [==============================] - 0s 154us/step - loss: 0.4690 - acc: 0.7646 - val_loss: 0.5452 - val_acc: 0.7520\n",
      "Epoch 49/50\n",
      "514/514 [==============================] - 0s 154us/step - loss: 0.4776 - acc: 0.7665 - val_loss: 0.5430 - val_acc: 0.7559\n",
      "Epoch 50/50\n",
      "514/514 [==============================] - 0s 155us/step - loss: 0.4535 - acc: 0.7899 - val_loss: 0.5202 - val_acc: 0.7441\n",
      "finished.\n",
      "768/768 [==============================] - 0s 17us/step\n",
      "Model accuracy: \n",
      "acc: 77.60%\n"
     ]
    }
   ],
   "source": [
    "# Compile Model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit Model using validation_split parameter\n",
    "model.fit(X,Y, epochs = 50, batch_size=10, verbose=1, validation_split=0.33)\n",
    "print(\"finished.\")\n",
    "\n",
    "# Evaluate Model\n",
    "scores = model.evaluate(X,Y)\n",
    "print(\"\\nModel accuracy: \\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Model evaluation using standard train test split **\n",
    "\n",
    "In this example we use the handy train test split() function from the Python scikit-learn machine learning library to separate our data into a training and test dataset. We use 67% for training and the remaining 33% of the data for validation. The validation dataset can be specified to the fit() function in Keras by the validation data argument. It takes a tuple of the input and output datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 514 samples, validate on 254 samples\n",
      "Epoch 1/50\n",
      "514/514 [==============================] - 0s 789us/step - loss: 0.4962 - acc: 0.7685 - val_loss: 0.5687 - val_acc: 0.7205\n",
      "Epoch 2/50\n",
      "514/514 [==============================] - 0s 157us/step - loss: 0.4866 - acc: 0.7549 - val_loss: 0.5448 - val_acc: 0.7362\n",
      "Epoch 3/50\n",
      "514/514 [==============================] - 0s 175us/step - loss: 0.4596 - acc: 0.7626 - val_loss: 0.5421 - val_acc: 0.7717\n",
      "Epoch 4/50\n",
      "514/514 [==============================] - 0s 157us/step - loss: 0.4603 - acc: 0.7665 - val_loss: 0.5445 - val_acc: 0.7402\n",
      "Epoch 5/50\n",
      "514/514 [==============================] - 0s 152us/step - loss: 0.4655 - acc: 0.7510 - val_loss: 0.5346 - val_acc: 0.7598\n",
      "Epoch 6/50\n",
      "514/514 [==============================] - 0s 159us/step - loss: 0.4542 - acc: 0.7802 - val_loss: 0.5364 - val_acc: 0.7638\n",
      "Epoch 7/50\n",
      "514/514 [==============================] - 0s 165us/step - loss: 0.4418 - acc: 0.7918 - val_loss: 0.5629 - val_acc: 0.7402\n",
      "Epoch 8/50\n",
      "514/514 [==============================] - 0s 176us/step - loss: 0.4429 - acc: 0.7938 - val_loss: 0.5610 - val_acc: 0.7480\n",
      "Epoch 9/50\n",
      "514/514 [==============================] - 0s 154us/step - loss: 0.4560 - acc: 0.7685 - val_loss: 0.5460 - val_acc: 0.7598\n",
      "Epoch 10/50\n",
      "514/514 [==============================] - 0s 171us/step - loss: 0.4692 - acc: 0.7724 - val_loss: 0.5668 - val_acc: 0.7441\n",
      "Epoch 11/50\n",
      "514/514 [==============================] - 0s 154us/step - loss: 0.4888 - acc: 0.7549 - val_loss: 0.5866 - val_acc: 0.7047\n",
      "Epoch 12/50\n",
      "514/514 [==============================] - 0s 158us/step - loss: 0.4503 - acc: 0.7821 - val_loss: 0.5305 - val_acc: 0.7874\n",
      "Epoch 13/50\n",
      "514/514 [==============================] - 0s 161us/step - loss: 0.4411 - acc: 0.7899 - val_loss: 0.5342 - val_acc: 0.7441\n",
      "Epoch 14/50\n",
      "514/514 [==============================] - 0s 164us/step - loss: 0.4509 - acc: 0.7879 - val_loss: 0.5308 - val_acc: 0.7913\n",
      "Epoch 15/50\n",
      "514/514 [==============================] - 0s 154us/step - loss: 0.4480 - acc: 0.7899 - val_loss: 0.5553 - val_acc: 0.7559\n",
      "Epoch 16/50\n",
      "514/514 [==============================] - 0s 161us/step - loss: 0.4537 - acc: 0.7704 - val_loss: 0.5462 - val_acc: 0.7402\n",
      "Epoch 17/50\n",
      "514/514 [==============================] - 0s 153us/step - loss: 0.4434 - acc: 0.7704 - val_loss: 0.5446 - val_acc: 0.7323\n",
      "Epoch 18/50\n",
      "514/514 [==============================] - 0s 171us/step - loss: 0.4447 - acc: 0.7840 - val_loss: 0.6762 - val_acc: 0.6614\n",
      "Epoch 19/50\n",
      "514/514 [==============================] - 0s 159us/step - loss: 0.4672 - acc: 0.7860 - val_loss: 0.5278 - val_acc: 0.7559\n",
      "Epoch 20/50\n",
      "514/514 [==============================] - 0s 168us/step - loss: 0.4710 - acc: 0.7568 - val_loss: 0.5639 - val_acc: 0.7480\n",
      "Epoch 21/50\n",
      "514/514 [==============================] - 0s 165us/step - loss: 0.4430 - acc: 0.7782 - val_loss: 0.5489 - val_acc: 0.7598\n",
      "Epoch 22/50\n",
      "514/514 [==============================] - 0s 162us/step - loss: 0.4615 - acc: 0.7724 - val_loss: 0.5273 - val_acc: 0.7638\n",
      "Epoch 23/50\n",
      "514/514 [==============================] - 0s 154us/step - loss: 0.4655 - acc: 0.7685 - val_loss: 0.5533 - val_acc: 0.7402\n",
      "Epoch 24/50\n",
      "514/514 [==============================] - 0s 166us/step - loss: 0.4454 - acc: 0.7821 - val_loss: 0.5606 - val_acc: 0.7323\n",
      "Epoch 25/50\n",
      "514/514 [==============================] - 0s 158us/step - loss: 0.4456 - acc: 0.7763 - val_loss: 0.6060 - val_acc: 0.7165\n",
      "Epoch 26/50\n",
      "514/514 [==============================] - 0s 162us/step - loss: 0.4531 - acc: 0.7782 - val_loss: 0.5433 - val_acc: 0.7402\n",
      "Epoch 27/50\n",
      "514/514 [==============================] - 0s 160us/step - loss: 0.4485 - acc: 0.7782 - val_loss: 0.5608 - val_acc: 0.7598\n",
      "Epoch 28/50\n",
      "514/514 [==============================] - 0s 156us/step - loss: 0.4637 - acc: 0.7743 - val_loss: 0.5477 - val_acc: 0.7520\n",
      "Epoch 29/50\n",
      "514/514 [==============================] - 0s 154us/step - loss: 0.4373 - acc: 0.7918 - val_loss: 0.5343 - val_acc: 0.7874\n",
      "Epoch 30/50\n",
      "514/514 [==============================] - 0s 165us/step - loss: 0.4433 - acc: 0.7860 - val_loss: 0.5440 - val_acc: 0.7283\n",
      "Epoch 31/50\n",
      "514/514 [==============================] - 0s 159us/step - loss: 0.4483 - acc: 0.7938 - val_loss: 0.5474 - val_acc: 0.7402\n",
      "Epoch 32/50\n",
      "514/514 [==============================] - 0s 169us/step - loss: 0.4614 - acc: 0.7665 - val_loss: 0.5362 - val_acc: 0.7402\n",
      "Epoch 33/50\n",
      "514/514 [==============================] - 0s 174us/step - loss: 0.4442 - acc: 0.7938 - val_loss: 0.5463 - val_acc: 0.7559\n",
      "Epoch 34/50\n",
      "514/514 [==============================] - 0s 159us/step - loss: 0.4398 - acc: 0.7840 - val_loss: 0.5307 - val_acc: 0.7913\n",
      "Epoch 35/50\n",
      "514/514 [==============================] - 0s 166us/step - loss: 0.4350 - acc: 0.7840 - val_loss: 0.5801 - val_acc: 0.7323\n",
      "Epoch 36/50\n",
      "514/514 [==============================] - 0s 151us/step - loss: 0.4484 - acc: 0.7704 - val_loss: 0.5552 - val_acc: 0.7598\n",
      "Epoch 37/50\n",
      "514/514 [==============================] - 0s 166us/step - loss: 0.4327 - acc: 0.7957 - val_loss: 0.5336 - val_acc: 0.7913\n",
      "Epoch 38/50\n",
      "514/514 [==============================] - 0s 159us/step - loss: 0.4415 - acc: 0.7782 - val_loss: 0.5324 - val_acc: 0.7677\n",
      "Epoch 39/50\n",
      "514/514 [==============================] - 0s 157us/step - loss: 0.4604 - acc: 0.7704 - val_loss: 0.6262 - val_acc: 0.6929\n",
      "Epoch 40/50\n",
      "514/514 [==============================] - 0s 164us/step - loss: 0.4756 - acc: 0.7802 - val_loss: 0.5351 - val_acc: 0.7638\n",
      "Epoch 41/50\n",
      "514/514 [==============================] - 0s 152us/step - loss: 0.4360 - acc: 0.7840 - val_loss: 0.5505 - val_acc: 0.7402\n",
      "Epoch 42/50\n",
      "514/514 [==============================] - 0s 148us/step - loss: 0.4461 - acc: 0.7724 - val_loss: 0.5709 - val_acc: 0.7283\n",
      "Epoch 43/50\n",
      "514/514 [==============================] - 0s 163us/step - loss: 0.4488 - acc: 0.7763 - val_loss: 0.5501 - val_acc: 0.7480\n",
      "Epoch 44/50\n",
      "514/514 [==============================] - 0s 169us/step - loss: 0.4442 - acc: 0.7918 - val_loss: 0.6107 - val_acc: 0.7008\n",
      "Epoch 45/50\n",
      "514/514 [==============================] - 0s 156us/step - loss: 0.4591 - acc: 0.7607 - val_loss: 0.5408 - val_acc: 0.7795\n",
      "Epoch 46/50\n",
      "514/514 [==============================] - 0s 172us/step - loss: 0.4427 - acc: 0.8035 - val_loss: 0.5433 - val_acc: 0.7598\n",
      "Epoch 47/50\n",
      "514/514 [==============================] - 0s 176us/step - loss: 0.4667 - acc: 0.7685 - val_loss: 0.6283 - val_acc: 0.7362\n",
      "Epoch 48/50\n",
      "514/514 [==============================] - 0s 163us/step - loss: 0.4567 - acc: 0.7840 - val_loss: 0.6004 - val_acc: 0.7480\n",
      "Epoch 49/50\n",
      "514/514 [==============================] - 0s 168us/step - loss: 0.4581 - acc: 0.7802 - val_loss: 0.5370 - val_acc: 0.7756\n",
      "Epoch 50/50\n",
      "514/514 [==============================] - 0s 178us/step - loss: 0.4418 - acc: 0.7957 - val_loss: 0.5366 - val_acc: 0.7559\n",
      "finished.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = .33, random_state = 7)\n",
    "\n",
    "# Compile Model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit Model using validation_split parameter\n",
    "model.fit(X_train,y_train, epochs = 50, batch_size=10, verbose=1, validation_data=(X_test,y_test))\n",
    "print(\"finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 0s 28us/step\n",
      "\n",
      "acc: 75.59%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Model\n",
    "scores = model.evaluate(X_test,y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Manual K-fold cross-validation with Keras **\n",
    "\n",
    "In the example below we use the handy StratifiedKFold class1 from the scikit-learn Python machine learning library to split up the training dataset into 10 folds. The folds are stratified, meaning that the algorithm attempts to balance the number of instances of each class in each fold. The example creates and evaluates 10 models using the 10 splits of the data and collects all of the scores. The verbose output for each epoch is turned off by passing verbose=0 to the fit() and evaluate() functions on the model. The performance is printed for each model and it is stored. The average and standard deviation of the model performance is then printed at the end of the run to provide a robust estimate of model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 75.32%\n",
      "acc: 75.32%\n",
      "acc: 71.43%\n",
      "acc: 84.42%\n",
      "acc: 79.22%\n",
      "acc: 81.82%\n",
      "acc: 68.83%\n",
      "acc: 70.13%\n",
      "acc: 65.79%\n",
      "acc: 75.00%\n",
      "74.73% (+/- 5.58%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
    "cv_scores = []\n",
    "\n",
    "for train, test in kfold.split(X,Y):\n",
    "    model = Sequential()\n",
    "    model.add( Dense(12, input_dim=8, activation='relu') )\n",
    "    model.add( Dense(8, activation='relu') )\n",
    "    model.add( Dense(1, activation='sigmoid') )\n",
    "\n",
    "    # Compile Model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Fit Model using validation_split parameter\n",
    "    model.fit(X[train], Y[train], epochs=150, batch_size=10, verbose=0)\n",
    "    \n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X[test], Y[test], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100)) \n",
    "   \n",
    "    cv_scores.append(scores[1] * 100)\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cv_scores), numpy.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Keras and Scikit-Learn **\n",
    "\n",
    "The Keras library provides a convenient wrapper for deep learning models to be used as classification or regression estimators in scikit-learn.\n",
    "\n",
    "The KerasClassifier and KerasRegressor classes in Keras take an argument build_fn which is the name of the function used to create and call your keras model. In the example below we define a function create model() that create a simple multilayer neural network for the problem.\n",
    "\n",
    "We pass this function name to the KerasClassifier class by the build fn argument. We also pass in additional arguments of epochs=150 and batch size=10. These are automatically bundled up and passed on to the fit() function which is called internally by the KerasClassifier class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.712371837959376\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create model required for KerasClassifier \n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add( Dense(12, input_dim=8, activation='relu') )\n",
    "    model.add( Dense(8, activation='relu') )\n",
    "    model.add( Dense(1, activation='sigmoid') )\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "    \n",
    "    return model\n",
    "\n",
    "seed = 7\n",
    "model = KerasClassifier(build_fn=create_model, epochs=150, batch_size=10, verbose=0)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Gridsearch for Parameter Optimization **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "512/512 [==============================] - 1s 3ms/step - loss: 4.1294 - acc: 0.6504\n",
      "Epoch 2/50\n",
      "512/512 [==============================] - 0s 324us/step - loss: 1.2775 - acc: 0.5957\n",
      "Epoch 3/50\n",
      "512/512 [==============================] - 0s 333us/step - loss: 0.8932 - acc: 0.6113\n",
      "Epoch 4/50\n",
      "512/512 [==============================] - 0s 355us/step - loss: 0.7817 - acc: 0.6250\n",
      "Epoch 5/50\n",
      "512/512 [==============================] - 0s 348us/step - loss: 0.7761 - acc: 0.6387\n",
      "Epoch 6/50\n",
      "512/512 [==============================] - 0s 373us/step - loss: 0.7148 - acc: 0.6641\n",
      "Epoch 7/50\n",
      "512/512 [==============================] - 0s 396us/step - loss: 0.7016 - acc: 0.6836\n",
      "Epoch 8/50\n",
      "512/512 [==============================] - 0s 345us/step - loss: 0.6553 - acc: 0.6797\n",
      "Epoch 9/50\n",
      "512/512 [==============================] - 0s 393us/step - loss: 0.6571 - acc: 0.6934\n",
      "Epoch 10/50\n",
      "512/512 [==============================] - 0s 425us/step - loss: 0.6585 - acc: 0.6777\n",
      "Epoch 11/50\n",
      "512/512 [==============================] - 0s 370us/step - loss: 0.6623 - acc: 0.6621\n",
      "Epoch 12/50\n",
      "512/512 [==============================] - 0s 349us/step - loss: 0.6405 - acc: 0.6836\n",
      "Epoch 13/50\n",
      "512/512 [==============================] - 0s 346us/step - loss: 0.6239 - acc: 0.6895\n",
      "Epoch 14/50\n",
      "512/512 [==============================] - 0s 362us/step - loss: 0.6399 - acc: 0.6719\n",
      "Epoch 15/50\n",
      "512/512 [==============================] - 0s 329us/step - loss: 0.6152 - acc: 0.6875\n",
      "Epoch 16/50\n",
      "512/512 [==============================] - 0s 314us/step - loss: 0.6176 - acc: 0.6758\n",
      "Epoch 17/50\n",
      "512/512 [==============================] - 0s 310us/step - loss: 0.5937 - acc: 0.7246\n",
      "Epoch 18/50\n",
      "512/512 [==============================] - 0s 353us/step - loss: 0.5898 - acc: 0.6973\n",
      "Epoch 19/50\n",
      "512/512 [==============================] - 0s 392us/step - loss: 0.6070 - acc: 0.7090\n",
      "Epoch 20/50\n",
      "512/512 [==============================] - 0s 385us/step - loss: 0.5885 - acc: 0.7305\n",
      "Epoch 21/50\n",
      "512/512 [==============================] - 0s 372us/step - loss: 0.5848 - acc: 0.7090\n",
      "Epoch 22/50\n",
      "512/512 [==============================] - 0s 335us/step - loss: 0.5715 - acc: 0.7324\n",
      "Epoch 23/50\n",
      "512/512 [==============================] - 0s 335us/step - loss: 0.5755 - acc: 0.7168\n",
      "Epoch 24/50\n",
      "512/512 [==============================] - 0s 367us/step - loss: 0.5800 - acc: 0.7012\n",
      "Epoch 25/50\n",
      "512/512 [==============================] - 0s 375us/step - loss: 0.5719 - acc: 0.7324\n",
      "Epoch 26/50\n",
      "512/512 [==============================] - 0s 347us/step - loss: 0.5702 - acc: 0.7305\n",
      "Epoch 27/50\n",
      "512/512 [==============================] - 0s 340us/step - loss: 0.5731 - acc: 0.7148\n",
      "Epoch 28/50\n",
      "512/512 [==============================] - 0s 317us/step - loss: 0.5641 - acc: 0.7246\n",
      "Epoch 29/50\n",
      "512/512 [==============================] - 0s 318us/step - loss: 0.5470 - acc: 0.7383\n",
      "Epoch 30/50\n",
      "512/512 [==============================] - 0s 316us/step - loss: 0.5604 - acc: 0.7305\n",
      "Epoch 31/50\n",
      "512/512 [==============================] - 0s 326us/step - loss: 0.5641 - acc: 0.7168\n",
      "Epoch 32/50\n",
      "512/512 [==============================] - 0s 406us/step - loss: 0.5674 - acc: 0.7246\n",
      "Epoch 33/50\n",
      "512/512 [==============================] - 0s 368us/step - loss: 0.5544 - acc: 0.7402\n",
      "Epoch 34/50\n",
      "512/512 [==============================] - 0s 337us/step - loss: 0.5552 - acc: 0.7188\n",
      "Epoch 35/50\n",
      "512/512 [==============================] - 0s 335us/step - loss: 0.5549 - acc: 0.7363\n",
      "Epoch 36/50\n",
      "512/512 [==============================] - 0s 342us/step - loss: 0.5377 - acc: 0.7520\n",
      "Epoch 37/50\n",
      "512/512 [==============================] - 0s 336us/step - loss: 0.5520 - acc: 0.7246\n",
      "Epoch 38/50\n",
      "512/512 [==============================] - 0s 336us/step - loss: 0.5226 - acc: 0.7402\n",
      "Epoch 39/50\n",
      "512/512 [==============================] - 0s 400us/step - loss: 0.5386 - acc: 0.7441\n",
      "Epoch 40/50\n",
      "512/512 [==============================] - 0s 359us/step - loss: 0.5340 - acc: 0.7285\n",
      "Epoch 41/50\n",
      "512/512 [==============================] - 0s 345us/step - loss: 0.5427 - acc: 0.7402\n",
      "Epoch 42/50\n",
      "512/512 [==============================] - 0s 305us/step - loss: 0.5381 - acc: 0.7480\n",
      "Epoch 43/50\n",
      "512/512 [==============================] - 0s 341us/step - loss: 0.5323 - acc: 0.7500\n",
      "Epoch 44/50\n",
      "512/512 [==============================] - 0s 348us/step - loss: 0.5287 - acc: 0.7520\n",
      "Epoch 45/50\n",
      "512/512 [==============================] - 0s 313us/step - loss: 0.5371 - acc: 0.7246\n",
      "Epoch 46/50\n",
      "512/512 [==============================] - 0s 315us/step - loss: 0.5254 - acc: 0.7578\n",
      "Epoch 47/50\n",
      "512/512 [==============================] - 0s 315us/step - loss: 0.5400 - acc: 0.7383\n",
      "Epoch 48/50\n",
      "512/512 [==============================] - 0s 314us/step - loss: 0.5369 - acc: 0.7461\n",
      "Epoch 49/50\n",
      "512/512 [==============================] - 0s 313us/step - loss: 0.5203 - acc: 0.7539\n",
      "Epoch 50/50\n",
      "512/512 [==============================] - 0s 314us/step - loss: 0.5150 - acc: 0.7480\n",
      "256/256 [==============================] - 1s 2ms/step\n",
      "512/512 [==============================] - 0s 188us/step\n",
      "Epoch 1/50\n",
      "512/512 [==============================] - 1s 3ms/step - loss: 1.7110 - acc: 0.5488\n",
      "Epoch 2/50\n",
      "512/512 [==============================] - 0s 340us/step - loss: 1.0391 - acc: 0.6055\n",
      "Epoch 3/50\n",
      "512/512 [==============================] - 0s 447us/step - loss: 0.8852 - acc: 0.6113\n",
      "Epoch 4/50\n",
      "512/512 [==============================] - 0s 385us/step - loss: 0.8424 - acc: 0.6387\n",
      "Epoch 5/50\n",
      "512/512 [==============================] - 0s 339us/step - loss: 0.8010 - acc: 0.6152\n",
      "Epoch 6/50\n",
      "512/512 [==============================] - 0s 328us/step - loss: 0.7688 - acc: 0.6543\n",
      "Epoch 7/50\n",
      "512/512 [==============================] - 0s 330us/step - loss: 0.7590 - acc: 0.6719\n",
      "Epoch 8/50\n",
      "512/512 [==============================] - 0s 319us/step - loss: 0.7227 - acc: 0.6523\n",
      "Epoch 9/50\n",
      "512/512 [==============================] - 0s 331us/step - loss: 0.7551 - acc: 0.6348\n",
      "Epoch 10/50\n",
      "512/512 [==============================] - 0s 324us/step - loss: 0.7411 - acc: 0.6504\n",
      "Epoch 11/50\n",
      "512/512 [==============================] - 0s 325us/step - loss: 0.7421 - acc: 0.6738\n",
      "Epoch 12/50\n",
      "512/512 [==============================] - 0s 323us/step - loss: 0.7506 - acc: 0.6348\n",
      "Epoch 13/50\n",
      "512/512 [==============================] - 0s 321us/step - loss: 0.7184 - acc: 0.6699\n",
      "Epoch 14/50\n",
      "512/512 [==============================] - 0s 325us/step - loss: 0.7124 - acc: 0.6777\n",
      "Epoch 15/50\n",
      "512/512 [==============================] - 0s 329us/step - loss: 0.6874 - acc: 0.6660\n",
      "Epoch 16/50\n",
      "512/512 [==============================] - 0s 322us/step - loss: 0.6928 - acc: 0.6680\n",
      "Epoch 17/50\n",
      "512/512 [==============================] - 0s 371us/step - loss: 0.6850 - acc: 0.6582\n",
      "Epoch 18/50\n",
      "512/512 [==============================] - 0s 335us/step - loss: 0.7026 - acc: 0.6406\n",
      "Epoch 19/50\n",
      "512/512 [==============================] - 0s 327us/step - loss: 0.6930 - acc: 0.6523\n",
      "Epoch 20/50\n",
      "512/512 [==============================] - 0s 330us/step - loss: 0.6849 - acc: 0.6758\n",
      "Epoch 21/50\n",
      "512/512 [==============================] - 0s 343us/step - loss: 0.6929 - acc: 0.6563\n",
      "Epoch 22/50\n",
      "512/512 [==============================] - 0s 336us/step - loss: 0.6606 - acc: 0.6738\n",
      "Epoch 23/50\n",
      "512/512 [==============================] - 0s 355us/step - loss: 0.6890 - acc: 0.6602\n",
      "Epoch 24/50\n",
      "512/512 [==============================] - 0s 336us/step - loss: 0.6591 - acc: 0.6797\n",
      "Epoch 25/50\n",
      "512/512 [==============================] - 0s 323us/step - loss: 0.6755 - acc: 0.6543\n",
      "Epoch 26/50\n",
      "512/512 [==============================] - 0s 336us/step - loss: 0.6775 - acc: 0.6738\n",
      "Epoch 27/50\n",
      "512/512 [==============================] - 0s 399us/step - loss: 0.6631 - acc: 0.6699\n",
      "Epoch 28/50\n",
      "512/512 [==============================] - 0s 484us/step - loss: 0.6787 - acc: 0.6602\n",
      "Epoch 29/50\n",
      "512/512 [==============================] - 0s 454us/step - loss: 0.6624 - acc: 0.6836\n",
      "Epoch 30/50\n",
      "512/512 [==============================] - 0s 372us/step - loss: 0.6999 - acc: 0.6328\n",
      "Epoch 31/50\n",
      "512/512 [==============================] - 0s 342us/step - loss: 0.6477 - acc: 0.6699\n",
      "Epoch 32/50\n",
      "512/512 [==============================] - 0s 329us/step - loss: 0.6722 - acc: 0.6797\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 349us/step - loss: 0.6329 - acc: 0.6719\n",
      "Epoch 34/50\n",
      "512/512 [==============================] - 0s 348us/step - loss: 0.6541 - acc: 0.6973\n",
      "Epoch 35/50\n",
      "512/512 [==============================] - 0s 412us/step - loss: 0.6362 - acc: 0.6816\n",
      "Epoch 36/50\n",
      "512/512 [==============================] - 0s 334us/step - loss: 0.6579 - acc: 0.6797\n",
      "Epoch 37/50\n",
      "512/512 [==============================] - 0s 314us/step - loss: 0.6584 - acc: 0.6484\n",
      "Epoch 38/50\n",
      "512/512 [==============================] - 0s 317us/step - loss: 0.6409 - acc: 0.7090\n",
      "Epoch 39/50\n",
      "512/512 [==============================] - 0s 317us/step - loss: 0.6428 - acc: 0.6836\n",
      "Epoch 40/50\n",
      "512/512 [==============================] - 0s 309us/step - loss: 0.6376 - acc: 0.6836\n",
      "Epoch 41/50\n",
      "512/512 [==============================] - 0s 348us/step - loss: 0.6321 - acc: 0.6816\n",
      "Epoch 42/50\n",
      "512/512 [==============================] - 0s 342us/step - loss: 0.6456 - acc: 0.6699\n",
      "Epoch 43/50\n",
      "512/512 [==============================] - 0s 316us/step - loss: 0.6535 - acc: 0.6875\n",
      "Epoch 44/50\n",
      "512/512 [==============================] - 0s 317us/step - loss: 0.6588 - acc: 0.6680\n",
      "Epoch 45/50\n",
      "512/512 [==============================] - 0s 327us/step - loss: 0.6430 - acc: 0.6699\n",
      "Epoch 46/50\n",
      "512/512 [==============================] - 0s 349us/step - loss: 0.6199 - acc: 0.7031\n",
      "Epoch 47/50\n",
      "512/512 [==============================] - 0s 350us/step - loss: 0.6368 - acc: 0.6973\n",
      "Epoch 48/50\n",
      "512/512 [==============================] - 0s 329us/step - loss: 0.6254 - acc: 0.6797\n",
      "Epoch 49/50\n",
      "512/512 [==============================] - 0s 325us/step - loss: 0.6324 - acc: 0.6641\n",
      "Epoch 50/50\n",
      "512/512 [==============================] - 0s 382us/step - loss: 0.6274 - acc: 0.6855\n",
      "256/256 [==============================] - 1s 2ms/step\n",
      "512/512 [==============================] - 0s 153us/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-dcfd95051f34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Fit Gride search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Summarize results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2474\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m         \u001b[0mfetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2476\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m   2478\u001b[0m                               **self.session_kwargs)\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m     \u001b[0;31m# hack for list_devices() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1291\u001b[0m                 run_metadata):\n\u001b[1;32m   1292\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1293\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1294\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1352\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m           tf_session.TF_ExtendGraph(\n\u001b[0;32m-> 1354\u001b[0;31m               self._session, graph_def.SerializeToString(), status)\n\u001b[0m\u001b[1;32m   1355\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "              \n",
    "def create_model(optimizer='rmsprop', init='glorot_uniform'):\n",
    "    # Create model\n",
    "    model = Sequential()\n",
    "    model.add( Dense(12, input_dim = 8, kernel_initializer = init, \n",
    "                     activation = 'relu') )\n",
    "    model.add( Dense(8, kernel_initializer=init, activation='relu') )\n",
    "    model.add( Dense(1, kernel_initializer=init, activation='sigmoid') )\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer,\n",
    "                 metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "\n",
    "# grid search parms\n",
    "optimizers = ['rmsprop', 'adam']\n",
    "inits = ['glorot_uniform', 'normal', 'uniform']\n",
    "epochs = [50, 100, 150]\n",
    "batches = [5,10,20]\n",
    "param_grid = { \"optimizer\": optimizers, \"epochs\":epochs, \n",
    "               \"batch_size\": batches, \"init\": inits }\n",
    "\n",
    "# Fit Gride search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid_result = grid.fit(X,Y)\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
